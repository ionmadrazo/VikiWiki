## Cross-lingual Readability Assessment Dataset in 6 Languages (VikiWiki)
This repository contains the dataset for the scientific article: "Is Cross-lingual Readability Assessment Possible?"". This is the result of a research collaboration between [Ion Madrazo Azpiazu](https://ionmadrazo.github.io/) and [Maria Soledad Pera](https://solepera.github.io/).

Please cite this work as follows:

```
    @article{madrazo:2019,
	author = {Ion Madrazo Azpiazu and Maria Soledad Pera},
	year = "2019",
	title = {Multiattentive Hierarchical Recurrent Neural Network Architecture for Multilingual Readability Assessment},
	journal = {In press},
	volume = "1",
	number = "1",
	pages = "1--18"
}
```

### Abstract

Most research efforts related to automatic readability assessment focus on the design of strategies that apply to a specific language. These state-of-the-art strategies are highly dependent on linguistic features that best suit the language for which they were intended, constraining their adaptability and making it difficult to determine whether they would remain effective if they were applied to estimate the level of difficulty of texts in other languages. In this paper, we present the results of a study designed to determine the feasibility of a cross-lingual readability assessment strategy. For doing so, we first analyzed the most common features used for readability assessment and determined their influence on the readability prediction process of six different languages:  English, Spanish, Basque, Italian, French, and Catalan. In addition, we developed a cross-lingual readability assessment strategy that serves as a means to empirically explore potential advantages of employing a single strategy (and set of features) for readability assessment in different languages, including inter-language prediction agreement and prediction accuracy improvement for low-resource languages.
